{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EROAwrOzmR_P"
   },
   "source": [
    "![人工智慧 - 自由團隊](https://raw.githubusercontent.com/chenkenanalytic/img/master/af/aifreeteam.png)\n",
    "\n",
    "\n",
    "<center>Welcome to the data deployment practice of Traditional Chinese Handwriting Dataset by AI . FREE Team.</center>\n",
    "<br>\n",
    "<center>歡迎大家來到 AI . FREE Team 所開發的繁體中文手寫資料部署實作。 </center>\n",
    "<br>\n",
    "\n",
    "<center>(Author: Chen Ken, Yen-Lin 博士；Date of published: 2020/4/21；AI . FREE Team Website: https://aifreeblog.herokuapp.com/)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料部署步驟說明       \n",
    "\n",
    "* 部署前準備:   \n",
    "  下載本專案且解壓縮 data 資料夾內的四個壓檔檔案至 D 槽  \n",
    "<p> \n",
    "* 部署資料:  \n",
    "  Step 1: 建立存放繁體中文手寫資料的資料夾( OutputPath )   \n",
    "  Step 2: 解壓縮壓縮檔，且將全部的資料移至 OutputPath    \n",
    "  Step 3: 依繁體中文單字建立子資料夾分類資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleaned_Folder = 'cleaned_data/'\n",
    "Unknown_Folder = 'unknown_data/'\n",
    "DrivePath = '/home/jovyan/esun_handwritten/Single_char_image_generator/output/labels/'\n",
    "OutputPath = '/home/jovyan/esun_handwritten/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "data = glob.glob(DrivePath + os.sep + '*')\n",
    "classes = open('./all_classes.txt', 'r').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_labels = []\n",
    "for file in data:\n",
    "    label = file.split('.')[0][-1]\n",
    "    if label in classes:\n",
    "        path = OutputPath + Cleaned_Folder + label\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path) # Create the new word folder in OutputPath.\n",
    "        shutil.move(file, path + '/' + file.split('/')[-1])\n",
    "    else:\n",
    "        path = OutputPath + Unknown_Folder\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path) # Create the new word folder in OutputPath.\n",
    "        shutil.move(file, path + file.split('/')[-1])\n",
    "        error_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./cleaned_data\"\n",
    "\n",
    "x_data_list = []\n",
    "y_data_list = []\n",
    "class_map = {}\n",
    "for roots, dirs, files in os.walk(data_path):\n",
    "    for each in files:\n",
    "        if each.find('checkpoint') == -1:\n",
    "            x_data_list.append(os.path.join(roots, each))\n",
    "            y_data_list.append(roots.split(\"/\")[-1])\n",
    "            if roots.split(\"/\")[-1] not in class_map:\n",
    "                class_map[roots.split(\"/\")[-1]]=each.split('_')[0]\n",
    "data = pd.DataFrame({'file':x_data_list, 'class':y_data_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./cleaned_data/阿/44466_阿.png</td>\n",
       "      <td>阿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./cleaned_data/阿/000009_阿.jpg</td>\n",
       "      <td>阿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./cleaned_data/阿/14602_阿.png</td>\n",
       "      <td>阿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./cleaned_data/阿/000002_阿.jpg</td>\n",
       "      <td>阿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./cleaned_data/阿/4266_阿.png</td>\n",
       "      <td>阿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80150</th>\n",
       "      <td>./cleaned_data/培/000007_培.jpg</td>\n",
       "      <td>培</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80151</th>\n",
       "      <td>./cleaned_data/培/45993_培.png</td>\n",
       "      <td>培</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80152</th>\n",
       "      <td>./cleaned_data/培/15696_培.png</td>\n",
       "      <td>培</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80153</th>\n",
       "      <td>./cleaned_data/培/000023_培.jpg</td>\n",
       "      <td>培</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80154</th>\n",
       "      <td>./cleaned_data/培/000012_培.jpg</td>\n",
       "      <td>培</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80155 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file class\n",
       "0       ./cleaned_data/阿/44466_阿.png     阿\n",
       "1      ./cleaned_data/阿/000009_阿.jpg     阿\n",
       "2       ./cleaned_data/阿/14602_阿.png     阿\n",
       "3      ./cleaned_data/阿/000002_阿.jpg     阿\n",
       "4        ./cleaned_data/阿/4266_阿.png     阿\n",
       "...                              ...   ...\n",
       "80150  ./cleaned_data/培/000007_培.jpg     培\n",
       "80151   ./cleaned_data/培/45993_培.png     培\n",
       "80152   ./cleaned_data/培/15696_培.png     培\n",
       "80153  ./cleaned_data/培/000023_培.jpg     培\n",
       "80154  ./cleaned_data/培/000012_培.jpg     培\n",
       "\n",
       "[80155 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = dict(data.groupby('class').count()['file'])\n",
    "txt_file = 'class_count.txt'\n",
    "with open(txt_file, 'w') as f:\n",
    "    for k, v in class_count.items():\n",
    "        f.write(k+','+str(100-v)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1=[]\n",
    "for i, file in enumerate(data.groupby('class')['file'].count()<=10):\n",
    "    if file is True:\n",
    "        data.groupby('class')\n",
    "        class1.append(sorted(data['class'].unique())[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "background    100\n",
       "other_word     55\n",
       "丁             100\n",
       "三             100\n",
       "上             100\n",
       "             ... \n",
       "黃             100\n",
       "黎             100\n",
       "鼎             100\n",
       "齊             100\n",
       "龍             100\n",
       "Name: file, Length: 802, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('class')['file'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "OutputPath = '/home/jovyan/esun_handwritten/cleaned_data/'\n",
    "for label in class1:\n",
    "    path = OutputPath + label + '/'\n",
    "    for roots, dirs, files in os.walk(path):\n",
    "        for each in files:\n",
    "            if each.find('checkpoint') == -1:\n",
    "                shutil.copyfile(path+each,path+each.split('.')[0]+'-Copy1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Traditional_Chinese_Handwriting_Dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
